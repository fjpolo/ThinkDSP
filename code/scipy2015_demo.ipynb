{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ThinkDSP\n",
    "========\n",
    "by Allen Downey (think-dsp.com)\n",
    "\n",
    "This notebook contains examples and demos for a SciPy 2015 talk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import thinkdsp\n",
    "import thinkplot\n",
    "\n",
    "import numpy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Signal represents a function that can be evaluated at an point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sig = thinkdsp.CosSignal(freq=440)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cosine signal at 440 Hz has a period of 2.3 ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sig.plot()\n",
    "thinkplot.config(xlabel='time (s)', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`make_wave` samples the signal at equally-space time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = cos_sig.make_wave(duration=0.5, framerate=11025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`make_audio` creates a widget that plays the Wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave.apodize()\n",
    "wave.make_audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`make_spectrum` returns a Spectrum object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum = wave.make_spectrum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cosine wave contains only one frequency component (no harmonics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum.plot()\n",
    "thinkplot.config(xlabel='frequency (Hz)', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A SawTooth signal has a more complex harmonic structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saw_sig = thinkdsp.SawtoothSignal(freq=440)\n",
    "saw_sig.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what it sounds like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saw_wave = saw_sig.make_wave(duration=0.5)\n",
    "saw_wave.make_audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's what the spectrum looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saw_wave.make_spectrum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a short violin performance from jcveliz on freesound.org:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin = thinkdsp.read_wave('92002__jcveliz__violin-origional.wav')\n",
    "violin.make_audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spectrogram shows the spectrum over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram = violin.make_spectrogram(seg_length=1024)\n",
    "spectrogram.plot(high=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select a segment where the pitch is constant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1.2\n",
    "duration = 0.6\n",
    "segment = violin.segment(start, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compute the spectrum of the segment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum = segment.make_spectrum()\n",
    "spectrum.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dominant and fundamental peak is at 438.3 Hz, which is a slightly flat A4 (about 7 cents). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum.peaks()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an aside, you can use the spectrogram to help extract the Parson's code and then identify the song."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parson's code: DUUDDUURDR\n",
    "\n",
    "Send it off to http://www.musipedia.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A chirp is a signal whose frequency varies continuously over time (like a trombone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "PI2 = 2 * math.pi\n",
    "\n",
    "class SawtoothChirp(thinkdsp.Chirp):\n",
    "    \"\"\"Represents a sawtooth signal with varying frequency.\"\"\"\n",
    "\n",
    "    def _evaluate(self, ts, freqs):\n",
    "        \"\"\"Helper function that evaluates the signal.\n",
    "\n",
    "        ts: float array of times\n",
    "        freqs: float array of frequencies during each interval\n",
    "        \"\"\"\n",
    "        dts = numpy.diff(ts)\n",
    "        dps = PI2 * freqs * dts\n",
    "        phases = numpy.cumsum(dps)\n",
    "        phases = numpy.insert(phases, 0, 0)\n",
    "        cycles = phases / PI2\n",
    "        frac, _ = numpy.modf(cycles)\n",
    "        ys = thinkdsp.normalize(thinkdsp.unbias(frac), self.amp)\n",
    "        return ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = SawtoothChirp(start=220, end=880)\n",
    "wave = signal.make_wave(duration=2, framerate=10000)\n",
    "segment = wave.segment(duration=0.06)\n",
    "segment.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram = wave.make_spectrogram(1024)\n",
    "spectrogram.plot()\n",
    "thinkplot.config(xlabel='time (s)', \n",
    "                 ylabel='frequency (Hz)', \n",
    "                 legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think it sounds like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave.apodize()\n",
    "wave.make_audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up next is one of the coolest examples in Think DSP.  It uses LTI system theory to characterize the acoustics of a recording space and simulate the effect this space would have on the sound of a violin performance.\n",
    "\n",
    "I'll start with a recording of a gunshot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = thinkdsp.read_wave('180960__kleeb__gunshot.wav')\n",
    "\n",
    "start = 0.12\n",
    "response = response.segment(start=start)\n",
    "response.shift(-start)\n",
    "\n",
    "response.normalize()\n",
    "response.plot()\n",
    "thinkplot.config(xlabel='time (s)', \n",
    "                 ylabel='amplitude', \n",
    "                 ylim=[-1.05, 1.05], \n",
    "                 legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you play this recording, you can hear the initial shot and several seconds of echos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.make_audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wave records the \"impulse response\" of the room where the gun was fired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load a recording of a violin performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = thinkdsp.read_wave('92002__jcveliz__violin-origional.wav')\n",
    "start = 0.11\n",
    "wave = wave.segment(start=start)\n",
    "wave.shift(-start)\n",
    "\n",
    "wave.truncate(len(response))\n",
    "wave.normalize()\n",
    "wave.plot()\n",
    "thinkplot.config(xlabel='time (s)', \n",
    "                 ylabel='amplitude', \n",
    "                 ylim=[-1.05, 1.05],\n",
    "                 legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And listen to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave.make_audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can figure out what the violin would sound like if it was played in the room where the gun was fired.  All we have to do is convolve the two waves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = wave.convolve(response)\n",
    "output.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave.plot(label='original')\n",
    "output.plot(label='convolved')\n",
    "thinkplot.config(xlabel='time (s)', ylabel='amplitude', ylim=[-1.05, 1.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's what it sounds like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.make_audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you think this example is black magic, you are not alone.   But there is a good reason why this works, and I do my best to explain it in Chapter 9.  So stay tuned.\n",
    "\n",
    "I'd like to thanks jcveliz and kleeb for making these recordings available from freesound.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
